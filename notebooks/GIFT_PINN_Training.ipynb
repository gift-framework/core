{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFT-Native PINN Training Notebook\n",
    "\n",
    "Train a Physics-Informed Neural Network with built-in GIFT algebraic structure\n",
    "to learn the G2 metric on K7.\n",
    "\n",
    "**Key Features:**\n",
    "- Fano plane structure constants (exact)\n",
    "- G2 adjoint representation (14 DOF instead of 35)\n",
    "- Target: det(g) = 65/32, ||T|| < 0.001\n",
    "\n",
    "**Runnable on Google Colab with free T4 GPU.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment for Colab)\n",
    "# !pip install torch numpy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone GIFT repository (uncomment for Colab)\n",
    "# !git clone https://github.com/gift-framework/core.git\n",
    "# %cd core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GIFT modules\n",
    "try:\n",
    "    from gift_core.nn.gift_native_pinn import (\n",
    "        GIFTNativePINN,\n",
    "        GIFTNativeLoss,\n",
    "        GIFTTrainConfig,\n",
    "        create_gift_native_pinn,\n",
    "        train_gift_native_pinn,\n",
    "        sample_k7_points,\n",
    "        export_analytical_form,\n",
    "        phi0_standard,\n",
    "        FANO_LINES,\n",
    "        B2, B3, DIM_G2, DET_G_TARGET_FLOAT, H_STAR,\n",
    "        TORSION_THRESHOLD,\n",
    "    )\n",
    "    print(\"GIFT modules loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Make sure you're in the gift-framework/core directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GIFT Constants\n",
    "\n",
    "Display the key GIFT constants that are hard-coded in the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GIFT Constants (Proven in Lean)\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"b2 (Second Betti number): {B2}\")\n",
    "print(f\"b3 (Third Betti number): {B3}\")\n",
    "print(f\"H* = b2 + b3 + 1 = {H_STAR}\")\n",
    "print(f\"dim(G2) = {DIM_G2}\")\n",
    "print(f\"det(g) target = 65/32 = {DET_G_TARGET_FLOAT:.6f}\")\n",
    "print(f\"Joyce torsion threshold = {TORSION_THRESHOLD}\")\n",
    "print()\n",
    "print(\"Fano plane lines:\")\n",
    "for i, line in enumerate(FANO_LINES):\n",
    "    print(f\"  Line {i}: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display phi0 structure\n",
    "phi0 = phi0_standard(normalize=True)\n",
    "print(f\"phi0 has {len(phi0)} components (C(7,3) = 35)\")\n",
    "print(f\"Non-zero components: {np.sum(np.abs(phi0) > 1e-10)}\")\n",
    "print(f\"phi0 norm: {np.linalg.norm(phi0):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Model\n",
    "\n",
    "Create the GIFT-native PINN with G2 structure built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model = create_gift_native_pinn(\n",
    "    num_frequencies=32,       # Fourier features\n",
    "    hidden_dims=[128, 128, 128],  # MLP architecture\n",
    "    perturbation_scale=0.01,  # Scale of delta_phi\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")\n",
    "print(f\"Output dimension: 14 (G2 adjoint) -> 35 (3-form)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "x_test = sample_k7_points(100, device)\n",
    "with torch.no_grad():\n",
    "    phi_test = model(x_test)\n",
    "    det_test = model.det_g(x_test)\n",
    "\n",
    "print(f\"Input shape: {x_test.shape}\")\n",
    "print(f\"Output (phi) shape: {phi_test.shape}\")\n",
    "print(f\"det(g) mean: {det_test.mean().item():.6f}\")\n",
    "print(f\"det(g) target: {DET_G_TARGET_FLOAT:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = GIFTTrainConfig(\n",
    "    epochs=5000,\n",
    "    batch_size=1024,\n",
    "    learning_rate=1e-3,\n",
    "    \n",
    "    # Loss weights\n",
    "    det_weight=100.0,     # Enforce det(g) = 65/32\n",
    "    torsion_weight=1.0,   # Minimize torsion\n",
    "    topo_weight=10.0,     # Topological constraint\n",
    "    sparse_weight=0.1,    # Encourage sparse solution\n",
    "    pd_weight=10.0,       # Positive definite metric\n",
    "    \n",
    "    # Early stopping\n",
    "    target_torsion=0.001,\n",
    "    target_det_error=1e-6,\n",
    "    \n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {config.epochs}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Learning rate: {config.learning_rate}\")\n",
    "print(f\"  Target torsion: {config.target_torsion}\")\n",
    "print(f\"  Target det error: {config.target_det_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "Train the PINN with curriculum learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual training loop with visualization\n",
    "loss_fn = GIFTNativeLoss(\n",
    "    det_weight=config.det_weight,\n",
    "    torsion_weight=config.torsion_weight,\n",
    "    topo_weight=config.topo_weight,\n",
    "    sparse_weight=config.sparse_weight,\n",
    "    pd_weight=config.pd_weight,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=100,\n",
    ")\n",
    "\n",
    "# History tracking\n",
    "history = {\n",
    "    'loss': [],\n",
    "    'torsion': [],\n",
    "    'det_error': [],\n",
    "    'lr': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "pbar = tqdm(range(config.epochs), desc=\"Training\")\n",
    "\n",
    "best_torsion = float('inf')\n",
    "best_state = None\n",
    "\n",
    "for epoch in pbar:\n",
    "    # Sample batch\n",
    "    x = sample_k7_points(config.batch_size, device)\n",
    "    \n",
    "    # Forward\n",
    "    optimizer.zero_grad()\n",
    "    loss, components = loss_fn(model, x, return_components=True)\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Record\n",
    "    history['loss'].append(loss.item())\n",
    "    history['torsion'].append(components['torsion'].item())\n",
    "    history['det_error'].append(components['det'].item())\n",
    "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    # Track best\n",
    "    if components['torsion'].item() < best_torsion:\n",
    "        best_torsion = components['torsion'].item()\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.set_postfix({\n",
    "        'loss': f\"{loss.item():.4f}\",\n",
    "        'torsion': f\"{components['torsion'].item():.6f}\",\n",
    "        'det_err': f\"{components['det'].item():.6f}\",\n",
    "    })\n",
    "    \n",
    "    # Early stopping\n",
    "    if (components['torsion'].item() < config.target_torsion and\n",
    "        components['det'].item() < config.target_det_error):\n",
    "        print(f\"\\nConverged at epoch {epoch}!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest torsion achieved: {best_torsion:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Loss curve\n",
    "axes[0, 0].semilogy(history['loss'])\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Total Loss')\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Torsion\n",
    "axes[0, 1].semilogy(history['torsion'], label='Torsion norm')\n",
    "axes[0, 1].axhline(y=config.target_torsion, color='g', linestyle='--', label=f'Target ({config.target_torsion})')\n",
    "axes[0, 1].axhline(y=TORSION_THRESHOLD, color='r', linestyle='--', label=f'Joyce threshold ({TORSION_THRESHOLD})')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Torsion Norm')\n",
    "axes[0, 1].set_title('Torsion Convergence')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Det(g) error\n",
    "axes[1, 0].semilogy(history['det_error'])\n",
    "axes[1, 0].axhline(y=config.target_det_error, color='g', linestyle='--', label=f'Target ({config.target_det_error})')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('|det(g) - 65/32|Â²')\n",
    "axes[1, 0].set_title('Determinant Error')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].semilogy(history['lr'])\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Learning Rate')\n",
    "axes[1, 1].set_title('Learning Rate Schedule')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on fresh samples\n",
    "n_eval = 10000\n",
    "x_eval = sample_k7_points(n_eval, device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    phi_eval = model(x_eval)\n",
    "    det_eval = model.det_g(x_eval)\n",
    "    torsion_eval = model.torsion_norm(x_eval)\n",
    "    adjoint_eval = model.get_adjoint_params(x_eval)\n",
    "\n",
    "print(\"Evaluation Results (n={:,})\".format(n_eval))\n",
    "print(\"=\" * 40)\n",
    "print(f\"det(g):\")\n",
    "print(f\"  Mean: {det_eval.mean().item():.8f}\")\n",
    "print(f\"  Std:  {det_eval.std().item():.8f}\")\n",
    "print(f\"  Target: {DET_G_TARGET_FLOAT:.8f}\")\n",
    "print(f\"  Error: {abs(det_eval.mean().item() - DET_G_TARGET_FLOAT):.2e}\")\n",
    "print()\n",
    "print(f\"Torsion norm:\")\n",
    "print(f\"  Mean: {torsion_eval.mean().item():.8f}\")\n",
    "print(f\"  Max:  {torsion_eval.max().item():.8f}\")\n",
    "print(f\"  Target: < {config.target_torsion}\")\n",
    "print(f\"  Joyce threshold: {TORSION_THRESHOLD}\")\n",
    "print()\n",
    "print(f\"G2 adjoint parameters:\")\n",
    "print(f\"  Mean abs: {adjoint_eval.abs().mean().item():.6f}\")\n",
    "print(f\"  Max abs:  {adjoint_eval.abs().max().item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize det(g) distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(det_eval.cpu().numpy(), bins=50, density=True, alpha=0.7)\n",
    "axes[0].axvline(x=DET_G_TARGET_FLOAT, color='r', linestyle='--', label='Target 65/32')\n",
    "axes[0].set_xlabel('det(g)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('det(g) Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Torsion histogram\n",
    "axes[1].hist(torsion_eval.cpu().numpy(), bins=50, density=True, alpha=0.7)\n",
    "axes[1].axvline(x=config.target_torsion, color='g', linestyle='--', label=f'Target {config.target_torsion}')\n",
    "axes[1].axvline(x=TORSION_THRESHOLD, color='r', linestyle='--', label=f'Joyce {TORSION_THRESHOLD}')\n",
    "axes[1].set_xlabel('Torsion norm')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Torsion Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('evaluation_histograms.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': {\n",
    "        'num_frequencies': model.fourier.num_frequencies,\n",
    "        'perturbation_scale': model.perturbation_scale,\n",
    "    },\n",
    "    'training_history': history,\n",
    "    'best_torsion': best_torsion,\n",
    "}, 'gift_pinn_trained.pt')\n",
    "\n",
    "print(\"Model saved to: gift_pinn_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export analytical form\n",
    "analytical_data = export_analytical_form(\n",
    "    model,\n",
    "    'phi_analytical_coefficients.json',\n",
    "    grid_resolution=32,\n",
    ")\n",
    "\n",
    "print(\"Analytical coefficients exported to: phi_analytical_coefficients.json\")\n",
    "print(f\"  Dominant modes extracted: {len(analytical_data.get('dominant_modes', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "Print final summary and success criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  GIFT-Native PINN Training Summary\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Check success criteria\n",
    "torsion_ok = torsion_eval.mean().item() < config.target_torsion\n",
    "det_ok = abs(det_eval.mean().item() - DET_G_TARGET_FLOAT) < config.target_det_error\n",
    "\n",
    "print(\"Success Criteria:\")\n",
    "print(f\"  [{'X' if torsion_ok else ' '}] Torsion < {config.target_torsion}: {torsion_eval.mean().item():.6f}\")\n",
    "print(f\"  [{'X' if det_ok else ' '}] |det(g) - 65/32| < {config.target_det_error}: {abs(det_eval.mean().item() - DET_G_TARGET_FLOAT):.2e}\")\n",
    "print()\n",
    "\n",
    "if torsion_ok and det_ok:\n",
    "    print(\"SUCCESS: All criteria met!\")\n",
    "else:\n",
    "    print(\"Training may need more epochs or tuning.\")\n",
    "\n",
    "print()\n",
    "print(\"Output files:\")\n",
    "print(\"  - gift_pinn_trained.pt: Model checkpoint\")\n",
    "print(\"  - phi_analytical_coefficients.json: Extracted coefficients\")\n",
    "print(\"  - training_curves.png: Training visualization\")\n",
    "print(\"  - evaluation_histograms.png: Evaluation plots\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
